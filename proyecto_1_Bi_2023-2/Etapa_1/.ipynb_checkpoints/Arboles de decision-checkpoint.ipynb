{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bcf0b95",
   "metadata": {},
   "source": [
    "\n",
    "<span > <h1 style=\"color:blue\">Modelado Analitica de Texto: Arboles de desición</h1></span>\n",
    "\n",
    "A continuación se va a presentar un modelo de clasificación usando arboles de desición de manera que se pueda predecir si una reseña podría llegar a ser positiva o negativa. Cabe resaltar que el perfilamiento y el analisis se encuentra en mayor detalle en el notebook con el nombre  Modelado_analitica_texto en la carpte Etapa 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae899da1",
   "metadata": {},
   "source": [
    "## 1.Cargar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "562172f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in c:\\users\\user\\anaconda3\\lib\\site-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in c:\\users\\user\\anaconda3\\lib\\site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in c:\\users\\user\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in c:\\users\\user\\anaconda3\\lib\\site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
      "Requirement already satisfied: num2words in c:\\users\\user\\anaconda3\\lib\\site-packages (0.5.12)\n",
      "Requirement already satisfied: docopt>=0.6.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from num2words) (0.6.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4168\\1990407790.py:7: DeprecationWarning: `import pandas_profiling` is going to be deprecated by April 1st. Please use `import ydata_profiling` instead.\n",
      "  from pandas_profiling import ProfileReport\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions \n",
    "!pip install num2words\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "import re, string, unicodedata\n",
    "from num2words import num2words\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "from ydata_profiling import ProfileReport\n",
    "%matplotlib qt\n",
    "\n",
    "import contractions\n",
    "import re, string, unicodedata\n",
    "from num2words import num2words\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "import inflect\n",
    "import contractions\n",
    "from langdetect import detect\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9962c1ff",
   "metadata": {},
   "source": [
    "## 2. Cargar Datos y limpieza \n",
    "La explicación de la limpiea se encuentra en el otro notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f798cc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textos_espanol</th>\n",
       "      <th>sdg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>El Grupo de Coordinación Interdepartamental as...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>Los maestros, administradores y estudiantes pu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>La financiación de la enseñanza secundaria sup...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>Reconociendo que las muertes por diabetes norm...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>En la recopilación de datos en todos los ámbit...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Textos_espanol  sdg\n",
       "2233  El Grupo de Coordinación Interdepartamental as...    5\n",
       "2658  Los maestros, administradores y estudiantes pu...    5\n",
       "1954  La financiación de la enseñanza secundaria sup...    4\n",
       "569   Reconociendo que las muertes por diabetes norm...    3\n",
       "2247  En la recopilación de datos en todos los ámbit...    5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datos = pd.read_excel(r'C:\\Users\\user\\Downloads\\proyecto_1_Bi_2023-2\\Datos\\cat_345.xlsx')\n",
    "df_datos.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ba93df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e07257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformacion = df_datos.copy()\n",
    "df_transformacion=df_transformacion.drop_duplicates(subset=['Textos_espanol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528eb426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stopwords.words('spanish'):\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def remove_specialCoders(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if  \"Ã¡\" in word:\n",
    "            new_word = re.sub(r'Ã¡', 'á', word)\n",
    "            new_words.append(new_word)\n",
    "        elif \"ao\" in word:\n",
    "            new_word = re.sub(r'ao', 'ú', word)\n",
    "            new_words.append(new_word)\n",
    "        elif \"Ã\" in word:\n",
    "            new_word = re.sub(r'Ã', 'í', word)\n",
    "            new_words.append(new_word)\n",
    "        elif \"a3\" in word:\n",
    "            new_word = re.sub(r'a3', 'ó', word)\n",
    "            new_words.append(new_word)\n",
    "        elif \"Ã©\" in word:\n",
    "            new_word = re.sub(r'Ã©', 'é', word)\n",
    "            new_words.append(new_word)\n",
    "    \n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"Replace all integer occurrences in a list of tokenized words with textual representation\"\"\"\n",
    "    if words is None:\n",
    "        return[]\n",
    "    p = inflect.engine()\n",
    "    new_words=[]\n",
    "    for word in words:\n",
    "        if word is not None: #verifica que la palabra no sea None.\n",
    "            if word.isdigit():\n",
    "                new_word = p.number_to_words(word)\n",
    "                new_words.append(new_word)\n",
    "            else:\n",
    "                new_words.append(word)\n",
    "    return new_words\n",
    "def preprocessing(words):\n",
    "\n",
    "    words = to_lowercase(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_stopwords(words)\n",
    "    words = remove_specialCoders(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87cbbb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformacion['words'] = df_transformacion['Textos_espanol'].apply(word_tokenize).apply(preprocessing) #Aplica la eliminación del ruido\n",
    "df_transformacion['words'] = df_transformacion['words'].apply(lambda x: ' '.join(map(str, x)))\n",
    "df_transformacion['words'] = df_transformacion['words'].apply(word_tokenize).apply(preprocessing) #Aplica la eliminación del ruido\n",
    "df_transformacion['words'] = df_transformacion['words'].apply(lambda x: ' '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd51f07",
   "metadata": {},
   "source": [
    "## 2.1. Matriz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a998c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       3\n",
       "2       3\n",
       "3       3\n",
       "4       3\n",
       "       ..\n",
       "2995    5\n",
       "2996    5\n",
       "2997    5\n",
       "2998    5\n",
       "2999    5\n",
       "Name: sdg, Length: 3000, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data, y_data = df_transformacion['words'],df_transformacion['sdg']\n",
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f4848f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 16852)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = CountVectorizer(binary=True)\n",
    "X_dummy = dummy.fit_transform(X_data)\n",
    "print(X_dummy.shape)\n",
    "X_dummy.toarray()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c7b798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nombre_caracteristica = dummy.get_feature_names_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195a523",
   "metadata": {},
   "source": [
    "## 3. Modelo con Arboles de desición:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5eb4ef",
   "metadata": {},
   "source": [
    "### 3.1. Variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "389058e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817c90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='sdg', data=df_transformacion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edc6751",
   "metadata": {},
   "source": [
    "### 3.2. Modelo 1:  Min samples 2 & default depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72ec8731",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_dummy, y_data, test_size=0.2, random_state=0)\n",
    "arbol = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "tree = arbol.fit(X_train,Y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "matriz= confusion_matrix(Y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab048681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1c5f16582d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(Y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95ee17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp= ConfusionMatrixDisplay(confusion_matrix=matriz,display_labels=arbol.classes_)\n",
    "disp.plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7768adda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.93      0.90      0.91       237\n",
      "           4       0.92      0.90      0.91       187\n",
      "           5       0.88      0.94      0.91       176\n",
      "\n",
      "    accuracy                           0.91       600\n",
      "   macro avg       0.91      0.91      0.91       600\n",
      "weighted avg       0.91      0.91      0.91       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8dc2c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(arbol, feature_names=dummy.get_feature_names_out(), filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a689297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.9116666666666666\n"
     ]
    }
   ],
   "source": [
    "precision = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "print(\"Precisión del modelo:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f217809",
   "metadata": {},
   "source": [
    "### 3.3 Model 2: Best tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d64f7297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "particiones = KFold(n_splits=10, shuffle=True, random_state = 0)\n",
    "param_grid = {'criterion':['gini', 'entropy'],'max_depth':[2, 8, 10, 20, 30, 50],'min_samples_split':[2,3,4,5,6,7,8,9,10]}\n",
    "tree = DecisionTreeClassifier(criterion='entropy',random_state=0)\n",
    "best_model = GridSearchCV(tree, param_grid, cv=particiones)\n",
    "best_model.fit(X_train, Y_train)\n",
    "print(best_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c694080f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1c5f2099650>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree = best_model.best_estimator_\n",
    "y_pred_train = best_tree.predict(X_train)\n",
    "y_pred_test = best_tree.predict(X_test)\n",
    "matriz= confusion_matrix(Y_test, y_pred_test)\n",
    "ConfusionMatrixDisplay.from_predictions(Y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77dcccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.92      0.95      0.94       237\n",
      "           4       0.95      0.91      0.93       187\n",
      "           5       0.92      0.93      0.92       176\n",
      "\n",
      "    accuracy                           0.93       600\n",
      "   macro avg       0.93      0.93      0.93       600\n",
      "weighted avg       0.93      0.93      0.93       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3615e7d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(best_tree, feature_names=dummy.get_feature_names_out(), filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e56189a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.93\n"
     ]
    }
   ],
   "source": [
    "precision = accuracy_score(Y_test, y_pred_test)\n",
    "\n",
    "print(\"Precisión del modelo:\", precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e71790d",
   "metadata": {},
   "source": [
    "### 3.4 Model 3: Tree with no parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d1be5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = DecisionTreeClassifier()\n",
    "modelo.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2dcb51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.9266666666666666\n"
     ]
    }
   ],
   "source": [
    "predicciones = modelo.predict(X_test)\n",
    "precision = accuracy_score(Y_test, predicciones)\n",
    "print(\"Precisión del modelo:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed13a00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1c5f2988710>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz= confusion_matrix(Y_test, predicciones)\n",
    "ConfusionMatrixDisplay.from_predictions(Y_test, predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77582118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.93      0.94      0.93       237\n",
      "           4       0.95      0.91      0.93       187\n",
      "           5       0.90      0.93      0.91       176\n",
      "\n",
      "    accuracy                           0.93       600\n",
      "   macro avg       0.93      0.93      0.93       600\n",
      "weighted avg       0.93      0.93      0.93       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, predicciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66c5366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(modelo, feature_names=dummy.get_feature_names_out(), filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860b3b8e",
   "metadata": {},
   "source": [
    "## Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb6ce4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Model (can also use single decision tree)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8e0fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random = RandomForestClassifier(random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7dcf2269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2d011a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.9816666666666667\n"
     ]
    }
   ],
   "source": [
    "predicciones = random.predict(X_test)\n",
    "precision = accuracy_score(Y_test, predicciones)\n",
    "print(\"Precisión del modelo:\", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec6a9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz= confusion_matrix(Y_test, predicciones)\n",
    "ConfusionMatrixDisplay.from_predictions(Y_test, predicciones)\n",
    "\n",
    "# Extract single tree\n",
    "estimator = random.estimators_[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "342edfc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.99      0.97      0.98       237\n",
      "           4       0.98      0.98      0.98       187\n",
      "           5       0.97      0.99      0.98       176\n",
      "\n",
      "    accuracy                           0.98       600\n",
      "   macro avg       0.98      0.98      0.98       600\n",
      "weighted avg       0.98      0.98      0.98       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, predicciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9587fea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## imprimir arbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f284cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. Conclusiones\n",
    "\n",
    "En general se puede ver que la presión está en un valor cercano al 69%, lo cual no es muy bueno. Esto ocurre en casi todos los modelos presentados anteriormente. En base a las metricas de los diferentes modelos se puede decir que los mojores modelos van en el siguiente orden:\n",
    "\n",
    "1. Modelo 3 con una presición del 0.699\n",
    "2. Modelo 2 con una presición con el 0.694\n",
    "3. Modelo 1 con una presición con un 0.691"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
